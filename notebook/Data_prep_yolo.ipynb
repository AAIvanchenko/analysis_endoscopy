{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017360e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import random\n",
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e606df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EndoscopyDataset(Dataset):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, root, slice_vals = None):\n",
    "        self.root = root\n",
    "        self.image_idx = 0\n",
    "        # Get annotations_list\n",
    "        image_files = [file.name for file in Path(root).iterdir() if file.suffix in ['.png', '.jpg']]\n",
    "#         print(len(image_files))\n",
    "        annotations = []\n",
    "        \n",
    "        for file in image_files:\n",
    "            annotation_path = Path(root, file + '.txt')\n",
    "            if annotation_path.is_file():\n",
    "                dict_annotation = self.__txt_to_dict(str(Path(root, file + '.txt')))\n",
    "                dict_annotation['image_path'] = file\n",
    "                annotations.append(dict_annotation)\n",
    "#         print(len(annotations))\n",
    "                \n",
    "        # Cut annotations_list by slice_vals\n",
    "        if slice_vals:\n",
    "            size = len(annotations)\n",
    "            random.seed(42)\n",
    "            random.shuffle(annotations)\n",
    "            annotations = annotations[int(size*slice_vals[0]) : int(size*slice_vals[1])]\n",
    "            \n",
    "        # Get images\n",
    "        self.images = []\n",
    "        for img_path in [str(Path(root, annotation['image_path'])) for annotation in annotations]:\n",
    "            img = cv.imread(img_path)\n",
    "            img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "            img = np.array(img)\n",
    "            self.images.append(img)\n",
    "            \n",
    "        # Get targets\n",
    "        self.targets = []\n",
    "        for idx, annotation in enumerate(annotations):\n",
    "            boxes = annotation[\"bndboxes\"]\n",
    "            labels = annotation[\"labels\"]\n",
    "            # scale boxes to [0..1]\n",
    "            height, width = self.images[idx].shape[:2]\n",
    "            boxes = list(map(lambda box : self.__convert((width, height), box), boxes))\n",
    "\n",
    "            target = {}\n",
    "            target[\"boxes\"] = boxes\n",
    "            target[\"labels\"] = labels\n",
    "            self.targets.append(target)\n",
    "                          \n",
    "    def __iter__(self):\n",
    "        self.image_idx = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.image_idx >= len(self.images):\n",
    "            raise StopIteration\n",
    "        img = self.images[self.image_idx].copy()\n",
    "        target = dict(self.targets[self.image_idx])\n",
    "        self.image_idx += 1\n",
    "        return img, target\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # load images and masks\n",
    "        img = self.images[idx].copy()\n",
    "        target = dict(self.targets[idx])\n",
    "\n",
    "        return img, target\n",
    "    \n",
    "    def __txt_to_dict(self, file: str):\n",
    "        \"\"\"Parse \n",
    "        \"bndboxes\": (x_cent,y_cent,width,height), \"labels\": (class), for each boxes in .txt file\n",
    "        and \"image_path\" with target images.\n",
    "        \"\"\" \n",
    "        \n",
    "        with open(file, 'r') as f:\n",
    "            lines = f.read().splitlines()\n",
    "\n",
    "        target = {}\n",
    "        target[\"bndboxes\"] = []\n",
    "        target[\"labels\"] = []\n",
    "        \n",
    "        for line in lines:\n",
    "            value = list(map(float, line.split()))\n",
    "            target[\"bndboxes\"].append(value[1:5])\n",
    "            target[\"labels\"].append(value[0])\n",
    "            \n",
    "        return target\n",
    "    \n",
    "    def __convert(self, size: tuple, box: list):\n",
    "        \"\"\"Takes as input:  (width, height) of an image\n",
    "                                (x_cent, y_cent, w, h) of the bounding box\n",
    "            and returns (x_cent, y_cent, w, h) in [0, 1] of the bounding box in yolo format.\n",
    "        \"\"\"   \n",
    "        dw = 1./size[0]\n",
    "        dh = 1./size[1]\n",
    "        x = box[0]*dw\n",
    "        w = box[2]*dw\n",
    "        y = box[1]*dh\n",
    "        h = box[3]*dh\n",
    "        x = x+1/2*w\n",
    "        y = y+1/2*h\n",
    "\n",
    "        return (x, y, w, h)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "        \n",
    "    def save(self, save_path, dataset_type, on_append=False):\n",
    "        \"\"\"Save dataset to save_path to dataset_type directory\"\"\"\n",
    "        image_path = os.path.join(save_path, \"images\", dataset_type)\n",
    "        labels_path = os.path.join(save_path, \"labels\", dataset_type)\n",
    "        os.makedirs(image_path, exist_ok=True)\n",
    "        os.makedirs(labels_path, exist_ok=True)\n",
    "        \n",
    "        if on_append:\n",
    "            numfile = len(os.listdir(os.path.join(save_path, \"images\", dataset_type)))\n",
    "        \n",
    "        for i, (img, target) in enumerate(self): \n",
    "            img = cv.cvtColor(img, cv.COLOR_RGB2BGR)\n",
    "            file_number = i\n",
    "            if on_append:\n",
    "                file_number += numfile\n",
    "            cv.imwrite(os.path.join(image_path, str(file_number)+\".png\"), img)\n",
    "            \n",
    "            labels = [[label, *box] for label, box in zip(target[\"labels\"], target[\"boxes\"])]\n",
    "            with open(os.path.join(labels_path, str(file_number)+\".txt\"), 'w') as output:\n",
    "                for row in labels:\n",
    "                    output.write(\"\\t\".join(list(map(str,row))) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "601e89aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_face_dataset = EndoscopyDataset(\"../data/detection/\", slice_vals=(0, 0.8))\n",
    "valid_face_dataset = EndoscopyDataset(\"../data/detection/\", slice_vals=(0.8, 1.0))\n",
    "\n",
    "train_face_dataset.save('../data_prep/detection','train')\n",
    "valid_face_dataset.save('../data_prep/detection','valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f395c7bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
