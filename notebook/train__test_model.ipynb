{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7a0edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "from tqdm.autonotebook import tqdm, trange\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce28921",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = Path(__file__).resolve()\n",
    "ROOT = FILE.parents[1] # program ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d219ee56",
   "metadata": {},
   "source": [
    "# Создание датасета для обучения и тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66303397",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Класс загрузки dataset\n",
    "\n",
    "    :list_classes: список классов.\n",
    "    :img_path_list: список путей до изображений.\n",
    "    :transform: список преобразовай dataset.\n",
    "    :img_list: список изображений.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_frame, transform: transforms.Compose = None):\n",
    "        \n",
    "        self.list_classes = data_frame['labels'].to_list()\n",
    "        self.img_path_list = data_frame['paths'].to_list()\n",
    "        self.transform = transform\n",
    "        self.img_list = []\n",
    "\n",
    "        for path in self.img_path_list:\n",
    "            img = self.__get_img_by_path(path)\n",
    "            self.img_list.append(img)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = {'image': self.img_list[index],\n",
    "                  'target':  self.list_classes[index]}\n",
    "    \n",
    "        if self.transform:\n",
    "            sample[\"image\"] = self.transform(self.img_list[index])\n",
    "\n",
    "        return sample\n",
    "\n",
    "    @staticmethod\n",
    "    def __get_img_by_path(img_path):\n",
    "        \"\"\"\n",
    "        Получение картинки по её пути.\n",
    "        :img_path: путь до картинки\n",
    "        :return: картинка, состаящая из массива цифр\n",
    "        \"\"\"\n",
    "        # чтобы картинки считывались и с русским путем\n",
    "        f = open(img_path, \"rb\");\n",
    "        chunk = f.read()\n",
    "        chunk_arr = np.frombuffer(chunk, dtype=np.uint8)\n",
    "        img = cv.imdecode(chunk_arr, cv.IMREAD_COLOR)\n",
    "        img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "        img = np.array(img)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20470b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(path_file_df):\n",
    "    df = pd.read_csv(path_file_df)\n",
    "    data = CreateDataset(df,transform=transforms.Compose([\n",
    "                            transforms.ToTensor(),\n",
    "                            transforms.Resize(size=(256,256))]))\n",
    "    \n",
    "    data_dl = DataLoader(data, batch_size=4, shuffle=True)\n",
    "    \n",
    "    return data_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a30810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883eb044",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5559d77",
   "metadata": {},
   "source": [
    "# Обучение и подсчет метрик на обучение и валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a7c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_metrics(data_dl, device, model, count_loss = False):\n",
    "    loss_func = nn.CrossEntropyLoss() if count_loss else None\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    f1_sc = 0\n",
    "    num = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for target in tqdm(data_dl):\n",
    "            xb, yb = target['image'].to(device),\\\n",
    "                     target['target'].to(device)\n",
    "            \n",
    "            if count_loss:\n",
    "                probs = model(xb)\n",
    "            else:\n",
    "                probs = model(xb.float())\n",
    "            \n",
    "            if count_loss:\n",
    "                loss_sum += loss_func(probs, yb).item()\n",
    "\n",
    "            _, preds = torch.max(probs, axis=-1)\n",
    "            correct += (preds == yb).sum().item()\n",
    "            num += len(xb)\n",
    "            f1_sc = f1_score(probs, yb, average='weighted', num_classes=2)\n",
    "     \n",
    "    \n",
    "    losses = (loss_sum / len(data_dl)) if count_loss else None\n",
    "    \n",
    "    accuracies = 100*correct / num\n",
    "    \n",
    "    # print(\"accuracies: \", accuracies)\n",
    "    # print(\"loss: \", losses)\n",
    "    # print(\"f1: \", f1_sc)\n",
    "    \n",
    "    return accuracies, f1_sc, losses\n",
    "\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl,device, lr_scale = 0.01):\n",
    "    \"\"\"\n",
    "    Обучение модели.\n",
    "\n",
    "    :param epochs: количество эпох.\n",
    "    :param model: модель, для обучения\n",
    "    .\n",
    "    :param loss_func: функция потерь сети.\n",
    "    :param opt: функция оптимизации.\n",
    "    :param train_dl: обучающая выборка.\n",
    "    :param valid_dl: валиационная выборка.\n",
    "    :return: массивы с метриками качества обученной модели.\n",
    "    \"\"\"\n",
    "    nbs = 64  # nominal batch size\n",
    "    accumulate = max(round(nbs / train_dl.batch_size), 1)  # accumulate loss before optimizing\n",
    "    \n",
    "    lf = lambda x: (1 - x / epochs) * (1.0 - lr_scale) + lr_scale # linear\n",
    "    scheduler = optim.lr_scheduler.LambdaLR(opt, lr_lambda=lf)  # plot_lr_scheduler(optimizer, scheduler, epochs)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accur = []\n",
    "    val_f1 = []\n",
    "    best_fitness = 0\n",
    "    best_acur = 0\n",
    "    for epoch in range(epochs):\n",
    "        print(\"epoch \", epoch)\n",
    "        model.train()\n",
    "        loss_sum = 0\n",
    "        last_opt_step = 0\n",
    "        for idx, target in enumerate(tqdm(train_dl)):\n",
    "            xb, yb = target['image'].to(device),\\\n",
    "                     target['target'].to(device)\n",
    "            \n",
    "            pred = model(xb)  # forward\n",
    "            loss = loss_func(pred, yb)  # loss scaled by batch_size\n",
    "            loss_sum += loss.item()\n",
    "            loss.backward()\n",
    "\n",
    "            if idx - last_opt_step >= accumulate:\n",
    "                opt.step()\n",
    "                opt.zero_grad()\n",
    "                last_opt_step = idx\n",
    "\n",
    "        print(\"train_loss: \", loss_sum / len(train_dl))\n",
    "        train_losses.append(loss_sum / len(train_dl))\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "        accuracies_val, f1_sc, losses_val = count_metrics(valid_dl, device,\n",
    "                                                   model, True)\n",
    "        print(\"valid loss: \", losses_val)\n",
    "        val_losses.append(losses_val)\n",
    "\n",
    "        print(\"valid accuracies: \", accuracies_val)\n",
    "        val_accur.append(accuracies_val)\n",
    "        \n",
    "        print(\"valid f1: \", f1_sc)\n",
    "        val_f1.append(f1_sc.item())\n",
    "        \n",
    "        if val_f1[-1] > best_fitness and accuracies_val > best_acur:\n",
    "            best_fitness = val_f1[-1]\n",
    "            best_acur = accuracies_val\n",
    "       \n",
    "            torch.save(model.state_dict(), Path(ROOT, 'models', 'model_best.pt'))\n",
    "        \n",
    "    return train_losses, val_losses, val_accur, val_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd2c0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training(train_losses, valid_losses, valid_accuracies):\n",
    "    \"\"\"\n",
    "    Отрисовка графиков после обучения.\n",
    "    Графики loss-функции на каждой эпохи.\n",
    "    График точности valid на каждой эпохи.\n",
    "\n",
    "    :train_losses: значение loss-функции на train каждая эпоха\n",
    "    :valid_losses: значение loss-функции на valid каждая эпоха\n",
    "    :valid_accuracies: точность на valid каждая эпоха\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 9))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.plot(train_losses, label=\"train_loss\")\n",
    "    plt.plot(valid_losses, label=\"valid_loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.plot(valid_accuracies, label=\"valid accuracy\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4faed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
